{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, shap, glob\n",
    "import numpy as np, pandas as pd, torchvision.transforms as transforms\n",
    "import random\n",
    "\n",
    "from feedback import *\n",
    "from tqdm.notebook import tqdm\n",
    "from torchvision.models import alexnet\n",
    "from torch.nn import Module\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from PIL import Image\n",
    "\n",
    "np.random.seed(2020)\n",
    "random.seed(2020)\n",
    "torch.manual_seed(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_weight_path ='./models/weights_Multiclass_Covid19(Non-kmer3)_IndexRemark.2022.03.30[NATCG]/'\n",
    "# save_weight_path = './models/weights_Multiclass_Covid19(Non-kmer3)_IndexRemark.2022.03.24[NACGTRYKMSWBDHV]/'\n",
    "\n",
    "weights_name = \"weights_Multiclass_Covid19(Non-kmer3)[NACGT].2022.03.30.pt\"\n",
    "# weights_name = \"weights_Multiclass_Covid19(Non-kmer3)[NACGTRYKMSWBDHV].2022.03.24.pt\"\n",
    "\n",
    "path2weights = os.path.join(save_weight_path,weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# npy_path = './np_image_totalunit/multiclass_totalunit/'\n",
    "npy_path = './np_image_totalunit/multiclass_nactg/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npy_data_list = [os.path.join(npy_path,'image_npy',i ) for i in sorted(os.listdir(os.path.join(npy_path,'image_npy')))]\n",
    "label_ = np.load(os.path.join(npy_path,'label.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nas_path = \"./dataset_1401/\"\n",
    "lineage_label = pd.read_csv('./dataset_1401/1404_lineage_report and metadata 20220316.csv')[['scorpio_call_y','diff','region']]\n",
    "lineage_label = np.array(lineage_label.fillna(\"None\"))\n",
    "label_s = []\n",
    "name_ = []\n",
    "new_lineage_label = []\n",
    "for idx, rna in enumerate(SeqIO.parse('./dataset_1401/1404.sequences.aln.fasta',\"fasta\")):\n",
    "    # print(lineage_label[idx][0].split(' ')[0])\n",
    "    label_s.append([lineage_label[idx][0].split(' ')[0], lineage_label[idx][2]])\n",
    "    name_.append(lineage_label[idx][0])\n",
    "    new_lineage_label.append(str(rna.seq).replace('-','N'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(npy_data_list, label_,stratify = label_, test_size=0.25, random_state=42)\n",
    "_, label_country, _, _ = train_test_split(label_s, label_,stratify = label_, test_size=0.25, random_state=42)\n",
    "print(len(X_train), len(y_train)) \n",
    "\n",
    "print(len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "import glob\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "np.random.seed(2020)\n",
    "random.seed(2020)\n",
    "torch.manual_seed(2020)\n",
    "\n",
    "class TransferDataset(Dataset):\n",
    "    def __init__(self, s_path, labels, transform):\n",
    "        self.transform = transform\n",
    "        self.s_path = s_path\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.s_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        singel_image_ = np.load(self.s_path[idx]).astype(np.float32)\n",
    "        seed = np.random.randint(1e9)       \n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        singel_image_ = self.transform(singel_image_)\n",
    "        label = int(self.labels[idx])\n",
    "        # print(label)\n",
    "\n",
    "        return singel_image_, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            # transforms.Normalize(mean, std),\n",
    "            ])     \n",
    "\n",
    "train_ds = TransferDataset(s_path= X_train, labels= y_train, transform= transformer)\n",
    "test_ds = TransferDataset(s_path= X_test, labels= y_test, transform= transformer)\n",
    "print(len(train_ds), len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, label = train_ds[10]\n",
    "batch_size = 32\n",
    "train_dl = DataLoader(train_ds, batch_size= batch_size, \n",
    "                        shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size= 2*batch_size, \n",
    "                        shuffle=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval\n",
    "models = alexnet(pretrained=False, num_classes=max(label_)+1)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "checkpoint = torch.load(path2weights, map_location=torch.device('cpu'))\n",
    "# checkpoint = torch.load('./models/weights_Multiclass_Covid19(Non-kmer3)_IndexRemark.2022.03.24[NACGTRYKMSWBDHV]/weights_Multiclass_Covid19(Non-kmer3)[NACGTRYKMSWBDHV].2022.03.24.pt', map_location=torch.device('cpu'))\n",
    "models.load_state_dict(checkpoint['model_state_dict'])\n",
    "models.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size= 1053, \n",
    "                        shuffle=False)\n",
    "test_dl = DataLoader(test_ds, batch_size= 351, \n",
    "                        shuffle=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'Alpha': 0, 'B.1.1.318-like': 1, 'Beta': 2, 'Delta': 3, 'Eta': 4, 'Gamma': 5, 'Iota': 6, 'Lambda': 7, 'Mu': 8, 'None': 9}\n",
    "models.eval()\n",
    "with torch.no_grad():\n",
    "    batch = next(iter(test_dl))\n",
    "    images, label = batch\n",
    "    pred = models(images.to(device))\n",
    "    Y_val = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since shuffle=True, this is a random sample of test data\n",
    "test_batch = next(iter(test_dl))\n",
    "t_images, t_label = test_batch\n",
    "\n",
    "batch_background = next(iter(train_dl))\n",
    "b_images, b_label = batch_background\n",
    "\n",
    "print(b_images.shape, b_label.shape)\n",
    "print(t_images.shape, t_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = shap.DeepExplainer(models, b_images.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_list = [[idx, image, label, country] for idx, (image, label, country) in enumerate(zip(X_test, y_test, label_country))]\n",
    "seq_index_list = [int(i[1][-8:-4]) for i in seq_list]\n",
    "# print(len(t_images), len(seq_index_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "# # save npy\n",
    "save_path = './shap_npy/multiclass_nactg_2022.03.30'\n",
    "# for idx, (img_, seq_n) in enumerate(tqdm(zip(t_images[150::],seq_list[150::]))):\n",
    "#     sav_name = seq_n[1][-8:-4]\n",
    "#     sv = e.shap_values(torch.unsqueeze(img_, axis=0))\n",
    "#     np.save(f\"{save_path}/{sav_name}.npy\", sv)\n",
    "#     # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_class = ['Alpha', 'B.1.1.318-like', 'Beta', 'Delta', 'Eta', 'Gamma', 'Iota', 'Lambda', 'Mu', 'None']\n",
    "location_map =np.load('./deepinsight_location_npy/coords_[NACGT]-multiclass=1404.npy')\n",
    "square_map = np.load('./deepinsight_location_npy/feature_density_matrix_[NACGT]-multiclass=1404.npy')\n",
    "total_sv_image_class_dict = {'Alpha': [], 'B.1.1.318-like':[], 'Beta':[], 'Delta':[], 'Eta':[], 'Gamma':[], 'Iota':[], 'Lambda':[], 'Mu':[], 'None':[]}\n",
    "\n",
    "for idx1, (exp_image, sv_npy) in enumerate(tqdm(zip(t_images, seq_list))):\n",
    "    if label_class[Y_val[idx1]]==label_class[np.argmax(pred.cpu().numpy(), axis=1)[idx1]]: # if ground truth == predict result\n",
    "        sav_name = sv_npy[1][-8:-4]\n",
    "\n",
    "        load_ = np.load(os.path.join(save_path,f\"{sav_name}.npy\"))\n",
    "        # print(load_.shape)\n",
    "        shap_numpy = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in load_]\n",
    "\n",
    "        # Extract Seq Image feature\n",
    "        image = np.squeeze(shap_numpy[np.argmax(pred.cpu().numpy(), axis=1)[idx1]])\n",
    "        image_sum = image[:,:,0]\n",
    "\n",
    "        single_seq = new_lineage_label[int(sav_name)] #get original sequence\n",
    "        important_location = {}\n",
    "        for  x_id, x_value in enumerate(image_sum):\n",
    "            for y_id, y_value in enumerate(x_value):\n",
    "                if y_value!=0:\n",
    "                    important_location[x_id,y_id] = round(y_value,10)\n",
    "                    # print(f\"[{x_id},{y_id}] = {round(y_value,4)}\")\n",
    "        Sample_filter_important_value_list = []\n",
    "        for idx2, (seq_rna, location_xy) in enumerate(zip(single_seq, location_map)):\n",
    "            if (location_xy[0], location_xy[1]) in (list(important_location.keys())):\n",
    "                # print(\"Seq Index: \",idx,\"Acid: \", seq_rna, \"Mat location [X, Y]: \",location_xy ,\"Value: \", important_location[location_xy[0], location_xy[1]])\n",
    "                Sample_filter_important_value_list.append([idx2, seq_rna, location_xy, important_location[location_xy[0], location_xy[1]]]) #save single sequnce index, epch [X, Y] position point, point weight\n",
    "        Sample_filter_important_value_list.sort(key = lambda s: s[3], reverse = True)\n",
    "        total_sv_image_class_dict[label_class[np.argmax(pred.cpu().numpy(), axis=1)[idx1]]].append([Sample_filter_important_value_list, sv_npy[3][1]]) #predict sequcne +  local country name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {}\n",
    "for classes in total_sv_image_class_dict:\n",
    "    class_dict[classes] = {}\n",
    "    if len(total_sv_image_class_dict[classes])!=0:\n",
    "        index_location_dict = {}\n",
    "        for single_seq in total_sv_image_class_dict[classes]:\n",
    "            for rna_position in single_seq[0]:\n",
    "                if (rna_position[0], rna_position[1]) not  in index_location_dict.keys():\n",
    "                    index_location_dict[rna_position[0], rna_position[1]] = rna_position[-1]\n",
    "                else:\n",
    "                    index_location_dict[rna_position[0], rna_position[1]] += rna_position[-1]\n",
    "        print(len(index_location_dict))\n",
    "        class_dict[classes] = index_location_dict\n",
    "        # #     break\n",
    "        # # break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in class_dict.keys():\n",
    "    class_dict[i] = {k: v for k, v in sorted(class_dict[i].items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "class_dict_minus_sign ={}\n",
    "for i in class_dict.keys():\n",
    "    class_dict_minus_sign[i] = {k: v for k, v in sorted(class_dict[i].items(), key=lambda item: item[1], reverse=False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in class_dict:\n",
    "    print(i, list(class_dict[i].keys())[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lineage_index = {'Alpha': 0, 'B.1.1.318-like':1, 'Beta':2, 'Delta':3, 'Eta':4, 'Gamma':5, 'Iota':6, 'Lambda':7, 'Mu':8, 'None':9}\n",
    "error_class_list = list(np.zeros(10).astype(np.int8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_seq_array = []\n",
    "for class_ in total_sv_image_class_dict:\n",
    "    if len(total_sv_image_class_dict[class_])>0:\n",
    "        for class_seq in total_sv_image_class_dict[class_]:\n",
    "            for single_se in class_seq[0]:\n",
    "                if single_se[0] ==7:\n",
    "                    error_seq_array.append([7, class_, class_seq[1], single_se[1]])\n",
    "                if single_se[0] ==17:\n",
    "                    error_seq_array.append([17, class_, class_seq[1], single_se[1]])\n",
    "                if single_se[0] ==217:\n",
    "                    error_seq_array.append([217, class_, class_seq[1], single_se[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.DataFrame(error_seq_array, columns=['Index Location', 'Lineage', 'Country', 'RNA'])).to_csv('./seven_error.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cefeaee0cb99e52f47ecbf6a0fec4d636206690d7e9c62031f057a9471691d65"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('lstm_pyt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
